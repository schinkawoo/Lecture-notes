cs321-20110920b-2up
audio: class2
start slide: 20/69 

IBMs initiative made for a purpose of making computers train and maintain themselves, similar to our autonomic 
nervous system.

IBM has sorted out so called self star properties. Main of them are self-configuration, self-optimization, self-healing, 
self-protection. 
-self-configuration(you can add devices, autonomicly insert itself in a right way, can start IP adresses
but also service discovery)
-self-optimization(???)
-self-healing(if there is a problem with one component it would self-heal or it could swith to additional equipment,
migrate to another machine)
-self-protection(in case of some atack, it could self-protect, take mesures, ?)
There are many moreself-aware, self-learning, operate in heterogeneous computing environment, anticipate and 
adapt to user needs. There are also different levels of quality that is not only reactive that adapts to something
new but can also anticipate what is coming.
-Term babysitting in todays case means that for some systems to be able to run over some extended period of
time humans have to be in the control loop. Thay need to look over the systems, to look what is the system doing,
to think about what to do and act to correct what could go wrong. Without humans in the loop things would break
down.
In one point IBM started being service company insted of hardware company. And it started to be bigger expense,
so the goal was to get people out of the loop, or as it is nicely put, to get people on the loop. Use less
people but still use some people.
The second level of the upgrade to Autonomic systems is to get engineers out of the loop, meaning that the
systems could construct the new solutions and eventualy inventing new algoritams trough clever way of learning.
-"Grand Challenge of building computing systems that regulate themselves". In simple terms put, new hardware and softvare is much cheaper to produce than install to the systems. For example: for one dollar spent on equipment, you need 10 dollars to spend on management. Hardware is cheap today, but keeping the hardware running is the main cost.
-Automatic means good preprogramed system that works well until everything goes as planed in programm. As soon as something goes the wrong way, the human intervention is needed.
 Autonomic on the other hand is a system that can self regulate in case itself in order to get a solution to given problem. And for that it doesent need humans intervention.
 // regretion test is a testing of the new upgrade of the system to be shure that the addition improves and not regreses the system(win, linux update) //
 Example with SW upgrades: Autonomic SW update would deply the SW, run it, test it and in case of any problems it could identify the component taht is causing problems, isolate it revert the whole instalation and re-start it without the probelm-causing part.
 -self-configuration
	In every system configuration there are an administrative or personal directives that are like guidelines for configuring the system. Underneeth of that the system does dhe right way of deploying, installing and configuring. For example in some company the games are banned on all computers in HR and as such they are not beeing included in update. Field workers laptops do not need database informations of employes because they are customer oriented. etc.

	self-configuration is needed in network configurations(configuring addresses, routes etc.). In parallel computing it is needed for resource assignig. Like in computing center with spare servers, it should put the servers on the right machine. In Multi Agent Systems(???). In complex systems is necessery for auto configure system depending on current envirement. It is not posible for human to predict all the posible scenarios that might happen cause it is too complex.
	
	Acording to IBM autonomic system is self-configuring, but self-configuring system is not necessarily autonomic.
-self-optimization

	It can be done in Design time, changing the software architecture for best preformance, in implementation time by the choice of algorithms, optimizing compiler etc.
	
	In computing center there is a lot of things that you can optimize. So much that it is geting harder and harder for people to understand it. For example, compilers have so many settings that it is sometines imposibile for a human to relize the best optimization pattern. IBM has came up with research paper about an algorithm that gets best optimization settings. Compiler optimization iz important for busines. For example Intel needs the best optimized compiler settings to show the best performance of its new chip.
	
	Runtime optimization is for example done with TCP that is optimizing the bandwith, and limiting it if necessary. It can adapt, but it is only parameter tyning. It is stil on the level of adaptation that is for now considered advanced, but it is stil another step to go to evolution inventing new solution.
	
	Optimization is not always linear process. It can often depend of different parammeters. For example WLAN, ethernet, GPRS - cost vs speed optimisation.
	
-self-healing
	Self healing is today mostly reactive. That means that at the point when something is already gone wrong, we activate the routine thati si trying to fix it. Proactive aproach is what we are trying to achive. Then we could predict failures.
	
	Solving some problem is done in couple of steps. First we need to find a cause of the failure, then to find a cure witch we then need to test and possibly deploy. IBM definition: The system automatically detects, and repairs localized software and hardware problems. It is distributed aproach where desision taking is done localy. The idea is that all the elements doing that will produce system that globaly works correctly.
	
	In computer systems the healing is mostly based on log analysing. Searching through the log files by looking for some alarm message or some strange patern form. After that the action takes place.
	
	Job languages are alanlized, and job is automaticly restarted.
	
	Database might have self diagnosing element that checks is interstate koherent or the recomputing the index file is needed.
	
	Hardware might have some signalling in case of overheating or power outige so it can send seafty message.
	
	IBM aproach is based on adding the self-healing features insted of implementing them from the start. Self-healing inside the application could be much more efficent by being able to choose algorithms form the start or change data structure.
	
	Still it is just choosing betveen parametars, and the main goal is integrity. The peace of code that understands his goal and have freedom to choose how to zchive that goal. It could go trough algorithm space. It has the ways of solving the problem but it can also invent the new way.  It means that code can change, not only the parameters.
-self protection
	Acording to IBM, self-protecting systems are the systems that can defend against malicious atacks, cascading failures and can prevent systemwide failures.
	
	It is a wery difficutl task to achive, because the attacks are not known in advance. It is also very hard to know what is good self-protecting system because there are not tests that show it. The main idea is that the infected part of the system be isolated without major consequences for whole system.
	
	Nowdays network monitoring system registers and disconects suspicious computers, semi or rearly fuly automatic. Systems ca also check if the client machines have latest paches and in that way prevent nown attacks.

IBM's proposed metodology says that the whole system needs to be broken into smaller but still autonomic entities each being dedicated to fufill specific task and by that reduces the complexity of designing a large system. To ensure an autonomic global functioning of all the elemensts, autonomic manager is nedeed. Manager is working on principle of CONTROL LOOP that checks the state in each element and acts acordingly. Manager needs to have SENSOR that colects data or states of the element. MONITOR colects and filters data from multiple sensors. Then the data is analyzed and compared to preset policies and golas. After that there is a need to determine if corrective actions need to be preformed. Then the action plan needs to be executed, so the managed element can be re-configured. In the complex system there are a lot of managers(for database, server, etc.). Its configuration depends of engineer.

POLICIES 







	
	